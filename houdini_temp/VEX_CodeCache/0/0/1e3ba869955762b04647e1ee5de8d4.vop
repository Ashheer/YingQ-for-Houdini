;_name	<vexpression>
; ModuleID = '__vex_snippet'
source_filename = "__vex_snippet"

@0 = private constant [11 x i8] c"goal_angle\00"
@1 = private constant [13 x i8] c"angle_spread\00"
@2 = private constant [15 x i8] c"min_slopeangle\00"
@3 = private constant [15 x i8] c"max_slopeangle\00"
@4 = private constant [10 x i8] c"sloperamp\00"
@5 = private constant [12 x i8] c"invertSlope\00"
@6 = private constant [8 x i8] c"dirramp\00"
@7 = private constant [12 x i8] c"maskbyslope\00"
@8 = private constant [10 x i8] c"maskbydir\00"
@9 = private constant [13 x i8] c"maskbyheight\00"
@10 = private constant [16 x i8] c"maskbycurvature\00"
@11 = private constant [16 x i8] c"maskbyocclusion\00"
@12 = private constant [10 x i8] c"minHeight\00"
@13 = private constant [10 x i8] c"maxHeight\00"
@14 = private constant [11 x i8] c"heightramp\00"
@15 = private constant [14 x i8] c"min_curvature\00"
@16 = private constant [14 x i8] c"max_curvature\00"
@17 = private constant [14 x i8] c"curvatureramp\00"
@18 = private constant [12 x i8] c"invert_mask\00"
@ix = external global i64
@iy = external global i64
@iz = external global i64
@mask = external global double
@height = external global double
@19 = private constant [3 x i8] c"ix\00"
@20 = private constant [3 x i8] c"iy\00"
@21 = private constant [3 x i8] c"iz\00"
@22 = private constant [5 x i8] c"mask\00"
@23 = private constant [7 x i8] c"height\00"

; Function Attrs: alwaysinline nounwind
define private void @"__vex_snippet_snippet@IIIFF"(i64* %_bound_ix, i64* %_bound_iy, i64* %_bound_iz, double* %_bound_mask, double* %_bound_height) #0 {
__llvm_entry:
  %return = call { double, <3 x double> } @"setcomp@FVFI"(<3 x double> zeroinitializer, double 1.000000e+00, i64 0)
  %output = extractvalue { double, <3 x double> } %return, 1
  %return3 = call { double, <3 x double> } @"setcomp@FVFI"(<3 x double> %output, double 0.000000e+00, i64 1)
  %output5 = extractvalue { double, <3 x double> } %return3, 1
  %_bound_ix6 = load i64, i64* %_bound_ix
  %cast = sitofp i64 %_bound_ix6 to double
  %_bound_iy7 = load i64, i64* %_bound_iy
  %cast8 = sitofp i64 %_bound_iy7 to double
  %_bound_iz9 = load i64, i64* %_bound_iz
  %cast10 = sitofp i64 %_bound_iz9 to double
  %return11 = call <3 x double> @"set@VFFF"(double %cast, double %cast8, double %cast10)
  %return12 = call double @"volumeindex@FIIV"(i64 1, i64 0, <3 x double> %return11)
  %return14 = call { double, <3 x double> } @"setcomp@FVFI"(<3 x double> %output5, double %return12, i64 2)
  %output16 = extractvalue { double, <3 x double> } %return14, 1
  %return18 = call { double, <3 x double> } @"setcomp@FVFI"(<3 x double> zeroinitializer, double 0.000000e+00, i64 0)
  %output20 = extractvalue { double, <3 x double> } %return18, 1
  %return22 = call { double, <3 x double> } @"setcomp@FVFI"(<3 x double> %output20, double 1.000000e+00, i64 1)
  %output24 = extractvalue { double, <3 x double> } %return22, 1
  %_bound_ix25 = load i64, i64* %_bound_ix
  %cast26 = sitofp i64 %_bound_ix25 to double
  %_bound_iy27 = load i64, i64* %_bound_iy
  %cast28 = sitofp i64 %_bound_iy27 to double
  %_bound_iz29 = load i64, i64* %_bound_iz
  %cast30 = sitofp i64 %_bound_iz29 to double
  %return31 = call <3 x double> @"set@VFFF"(double %cast26, double %cast28, double %cast30)
  %return32 = call double @"volumeindex@FIIV"(i64 1, i64 1, <3 x double> %return31)
  %return34 = call { double, <3 x double> } @"setcomp@FVFI"(<3 x double> %output24, double %return32, i64 2)
  %output36 = extractvalue { double, <3 x double> } %return34, 1
  %return38 = call <3 x double> @"normalize@VV"(<3 x double> %output16)
  %return40 = call <3 x double> @"normalize@VV"(<3 x double> %output36)
  %return43 = call <3 x double> @"cross@VVV"(<3 x double> %return38, <3 x double> %return40)
  %return45 = call <3 x double> @"normalize@VV"(<3 x double> %return43)
  %return47 = call double @"getcomp@FVI"(<3 x double> %return45, i64 2)
  %return48 = call double @"acos@FF"(double %return47)
  %return49 = call double @"degrees@FF"(double %return48)
  %return51 = call double @"getcomp@FVI"(<3 x double> %return45, i64 0)
  %return53 = call double @"getcomp@FVI"(<3 x double> %return45, i64 1)
  %return54 = call double @"atan2@FFF"(double %return51, double %return53)
  %return55 = call double @"degrees@FF"(double %return54)
  %return56 = call double @"ch@FS"(i8* getelementptr inbounds ([11 x i8], [11 x i8]* @0, i64 0, i64 0))
  %return57 = call double @"ch@FS"(i8* getelementptr inbounds ([13 x i8], [13 x i8]* @1, i64 0, i64 0))
  %output60 = fsub double %return55, %return56
  %return62 = call double @"mod@FFF"(double %output60, double 3.600000e+02)
  %output64 = fsub double %return62, 1.800000e+02
  %return67 = call double @"neg@FF"(double %return57)
  %return69 = call double @"fit@FFFFFF"(double %output64, double %return67, double %return57, double 0.000000e+00, double 1.000000e+00)
  %return71 = call double @"ch@FS"(i8* getelementptr inbounds ([15 x i8], [15 x i8]* @2, i64 0, i64 0))
  %return72 = call double @"ch@FS"(i8* getelementptr inbounds ([15 x i8], [15 x i8]* @3, i64 0, i64 0))
  %return73 = call double @"fit@FFFFFF"(double %return49, double %return71, double %return72, double 0.000000e+00, double 1.000000e+00)
  %return75 = call double @"chramp@FSF"(i8* getelementptr inbounds ([10 x i8], [10 x i8]* @4, i64 0, i64 0), double %return73)
  %return76 = call i64 @"chi@IS"(i8* getelementptr inbounds ([12 x i8], [12 x i8]* @5, i64 0, i64 0))
  %return77 = call i64 @"eq@III"(i64 %return76, i64 1)
  %0 = icmp ne i64 %return77, 0
  br i1 %0, label %true, label %end

true:                                             ; preds = %__llvm_entry
  %output79 = fsub double 1.000000e+00, %return75
  br label %end

end:                                              ; preds = %true, %__llvm_entry
  %slope.0 = phi double [ %output79, %true ], [ %return75, %__llvm_entry ]
  %return81 = call double @"chramp@FSF"(i8* getelementptr inbounds ([8 x i8], [8 x i8]* @6, i64 0, i64 0), double %return69)
  store double 1.000000e+00, double* %_bound_mask
  %return82 = call i64 @"chi@IS"(i8* getelementptr inbounds ([12 x i8], [12 x i8]* @7, i64 0, i64 0))
  %return83 = call i64 @"not@II"(i64 %return82)
  %return84 = call i64 @"chi@IS"(i8* getelementptr inbounds ([10 x i8], [10 x i8]* @8, i64 0, i64 0))
  %return85 = call i64 @"not@II"(i64 %return84)
  %return86 = call i64 @"and@III"(i64 %return83, i64 %return85)
  %return87 = call i64 @"chi@IS"(i8* getelementptr inbounds ([13 x i8], [13 x i8]* @9, i64 0, i64 0))
  %return88 = call i64 @"not@II"(i64 %return87)
  %return89 = call i64 @"and@III"(i64 %return86, i64 %return88)
  %return90 = call i64 @"chi@IS"(i8* getelementptr inbounds ([16 x i8], [16 x i8]* @10, i64 0, i64 0))
  %return91 = call i64 @"not@II"(i64 %return90)
  %return92 = call i64 @"and@III"(i64 %return89, i64 %return91)
  %return93 = call i64 @"chi@IS"(i8* getelementptr inbounds ([16 x i8], [16 x i8]* @11, i64 0, i64 0))
  %return94 = call i64 @"not@II"(i64 %return93)
  %return95 = call i64 @"and@III"(i64 %return92, i64 %return94)
  %1 = icmp ne i64 %return95, 0
  br i1 %1, label %true96, label %end97

true96:                                           ; preds = %end
  store double 0.000000e+00, double* %_bound_mask
  br label %end97

end97:                                            ; preds = %true96, %end
  %2 = icmp ne i64 %return82, 0
  br i1 %2, label %true99, label %end100

true99:                                           ; preds = %end97
  %_bound_mask101 = load double, double* %_bound_mask
  %output103 = fmul double %_bound_mask101, %slope.0
  store double %output103, double* %_bound_mask
  br label %end100

end100:                                           ; preds = %true99, %end97
  %3 = icmp ne i64 %return84, 0
  br i1 %3, label %true105, label %end106

true105:                                          ; preds = %end100
  %_bound_mask107 = load double, double* %_bound_mask
  %output109 = fmul double %_bound_mask107, %return81
  store double %output109, double* %_bound_mask
  br label %end106

end106:                                           ; preds = %true105, %end100
  %4 = icmp ne i64 %return87, 0
  br i1 %4, label %true111, label %end112

true111:                                          ; preds = %end106
  %_bound_height113 = load double, double* %_bound_height
  %return114 = call double @"chf@FS"(i8* getelementptr inbounds ([10 x i8], [10 x i8]* @12, i64 0, i64 0))
  %return115 = call double @"chf@FS"(i8* getelementptr inbounds ([10 x i8], [10 x i8]* @13, i64 0, i64 0))
  %return116 = call double @"fit@FFFFFF"(double %_bound_height113, double %return114, double %return115, double 0.000000e+00, double 1.000000e+00)
  %_bound_mask117 = load double, double* %_bound_mask
  %return119 = call double @"chramp@FSF"(i8* getelementptr inbounds ([11 x i8], [11 x i8]* @14, i64 0, i64 0), double %return116)
  %output120 = fmul double %_bound_mask117, %return119
  store double %output120, double* %_bound_mask
  br label %end112

end112:                                           ; preds = %true111, %end106
  %5 = icmp ne i64 %return90, 0
  br i1 %5, label %true122, label %end123

true122:                                          ; preds = %end112
  %_bound_ix124 = load i64, i64* %_bound_ix
  %cast125 = sitofp i64 %_bound_ix124 to double
  %_bound_iy126 = load i64, i64* %_bound_iy
  %cast127 = sitofp i64 %_bound_iy126 to double
  %_bound_iz128 = load i64, i64* %_bound_iz
  %cast129 = sitofp i64 %_bound_iz128 to double
  %return130 = call <3 x double> @"set@VFFF"(double %cast125, double %cast127, double %cast129)
  %return131 = call double @"volumeindex@FIIV"(i64 2, i64 0, <3 x double> %return130)
  %return132 = call double @"neg@FF"(double %return131)
  %return134 = call double @"chf@FS"(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @15, i64 0, i64 0))
  %return135 = call double @"chf@FS"(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @16, i64 0, i64 0))
  %return136 = call double @"fit@FFFFFF"(double %return132, double %return134, double %return135, double 0.000000e+00, double 1.000000e+00)
  %_bound_mask137 = load double, double* %_bound_mask
  %return139 = call double @"chramp@FSF"(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @17, i64 0, i64 0), double %return136)
  %output140 = fmul double %_bound_mask137, %return139
  store double %output140, double* %_bound_mask
  br label %end123

end123:                                           ; preds = %true122, %end112
  %6 = icmp ne i64 %return93, 0
  br i1 %6, label %true142, label %end143

true142:                                          ; preds = %end123
  %_bound_ix144 = load i64, i64* %_bound_ix
  %cast145 = sitofp i64 %_bound_ix144 to double
  %_bound_iy146 = load i64, i64* %_bound_iy
  %cast147 = sitofp i64 %_bound_iy146 to double
  %_bound_iz148 = load i64, i64* %_bound_iz
  %cast149 = sitofp i64 %_bound_iz148 to double
  %return150 = call <3 x double> @"set@VFFF"(double %cast145, double %cast147, double %cast149)
  %return151 = call double @"volumeindex@FIIV"(i64 3, i64 0, <3 x double> %return150)
  %_bound_mask152 = load double, double* %_bound_mask
  %output154 = fmul double %_bound_mask152, %return151
  store double %output154, double* %_bound_mask
  br label %end143

end143:                                           ; preds = %true142, %end123
  %return155 = call i64 @"chi@IS"(i8* getelementptr inbounds ([12 x i8], [12 x i8]* @18, i64 0, i64 0))
  %7 = icmp ne i64 %return155, 0
  br i1 %7, label %true156, label %end157

true156:                                          ; preds = %end143
  %_bound_mask158 = load double, double* %_bound_mask
  %output159 = fsub double 1.000000e+00, %_bound_mask158
  store double %output159, double* %_bound_mask
  br label %end157

end157:                                           ; preds = %true156, %end143
  ret void
}

; Function Attrs: alwaysinline
define private { double, <3 x double> } @"setcomp@FVFI"(<3 x double> %rw11, double %rw22, i64 %rw33) #1 {
__llvm_entry:
  %rw16 = call <3 x double> @"setcomp@VFI"(<3 x double> %rw11, double %rw22, i64 %rw33)
  %mrv = insertvalue { double, <3 x double> } undef, double %rw22, 0
  %mrv9 = insertvalue { double, <3 x double> } %mrv, <3 x double> %rw16, 1
  ret { double, <3 x double> } %mrv9
}

; Function Attrs: nounwind readnone
declare <3 x double> @"setcomp@VFI"(<3 x double>, double, i64) #2

; Function Attrs: nounwind readnone
declare <3 x double> @"set@VFFF"(double, double, double) #2

; Function Attrs: nounwind
declare double @"volumeindex@FIIV"(i64, i64, <3 x double>) #3

; Function Attrs: nounwind
declare <3 x double> @"normalize@VV"(<3 x double>) #3

; Function Attrs: nounwind
declare <3 x double> @"cross@VVV"(<3 x double>, <3 x double>) #3

; Function Attrs: nounwind readnone
declare double @"getcomp@FVI"(<3 x double>, i64) #2

; Function Attrs: nounwind readnone
declare double @"acos@FF"(double) #2

; Function Attrs: nounwind
declare double @"degrees@FF"(double) #3

; Function Attrs: nounwind readnone
declare double @"atan2@FFF"(double, double) #2

; Function Attrs: nounwind readnone
declare double @"ch@FS"(i8*) #2

; Function Attrs: nounwind readnone
declare double @"mod@FFF"(double, double) #2

; Function Attrs: nounwind readnone
declare double @"neg@FF"(double) #2

; Function Attrs: nounwind
declare double @"fit@FFFFFF"(double, double, double, double, double) #3

; Function Attrs: nounwind readnone
declare double @"chramp@FSF"(i8*, double) #2

; Function Attrs: nounwind readnone
declare i64 @"chi@IS"(i8*) #2

; Function Attrs: nounwind readnone
declare i64 @"eq@III"(i64, i64) #2

; Function Attrs: nounwind readnone
declare i64 @"not@II"(i64) #2

; Function Attrs: nounwind readnone
declare i64 @"and@III"(i64, i64) #2

; Function Attrs: nounwind readnone
declare double @"chf@FS"(i8*) #2

; Function Attrs: nounwind
define void @__vex_snippet(i64 %ix, i64 %iy, i64 %iz, double %mask, double %height) #3 {
__llvm_entry:
  %"<mask>" = alloca double
  %0 = alloca i64
  %1 = alloca i64
  %2 = alloca i64
  %3 = alloca double
  store double %mask, double* %"<mask>"
  store i64 %ix, i64* %0
  store i64 %iy, i64* %1
  store i64 %iz, i64* %2
  store double %height, double* %3
  call void @"__vex_snippet_snippet@IIIFF"(i64* %0, i64* %1, i64* %2, double* %"<mask>", double* %3)
  %gvalue = call i64 @"_export@ISI"(i8* getelementptr inbounds ([3 x i8], [3 x i8]* @19, i64 0, i64 0), i64 %ix) #4
  %gvalue6 = call i64 @"_export@ISI"(i8* getelementptr inbounds ([3 x i8], [3 x i8]* @20, i64 0, i64 0), i64 %iy) #4
  %gvalue8 = call i64 @"_export@ISI"(i8* getelementptr inbounds ([3 x i8], [3 x i8]* @21, i64 0, i64 0), i64 %iz) #4
  %evalue9 = load double, double* %"<mask>"
  %gvalue10 = call double @"_export@FSF"(i8* getelementptr inbounds ([5 x i8], [5 x i8]* @22, i64 0, i64 0), double %evalue9) #4
  %gvalue12 = call double @"_export@FSF"(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @23, i64 0, i64 0), double %height) #4
  store i64 %gvalue, i64* @ix
  store i64 %gvalue6, i64* @iy
  store i64 %gvalue8, i64* @iz
  store double %gvalue10, double* @mask
  store double %gvalue12, double* @height
  ret void
}

declare i64 @"_export@ISI"(i8*, i64)

declare double @"_export@FSF"(i8*, double)

define void @__shader_default_arguments() {
__llvm_entry:
  call void @__vex_snippet(i64 0, i64 0, i64 0, double 0.000000e+00, double 0.000000e+00)
  ret void
}

attributes #0 = { alwaysinline nounwind }
attributes #1 = { alwaysinline }
attributes #2 = { nounwind readnone }
attributes #3 = { nounwind }
attributes #4 = { nounwind readonly }

!context = !{!0}
!version = !{!1}
!precision = !{!2}

!0 = !{!"cvex"}
!1 = !{!"19.0.531"}
!2 = !{!"64"}

;_code_end
