;_name	<vexpression>
; ModuleID = '__vex_snippet'
source_filename = "__vex_snippet"

@0 = private constant [7 x i8] c"orient\00"
@1 = private constant [2 x i8] c"P\00"
@ptnum = external global i64
@orient = external global <4 x double>
@__rest_orient = external global <4 x double>
@pivot = external global <3 x double>
@2 = private constant [6 x i8] c"ptnum\00"
@3 = private constant [14 x i8] c"__rest_orient\00"
@4 = private constant [6 x i8] c"pivot\00"

; Function Attrs: alwaysinline nounwind
define private void @"__vex_snippet_snippet@IPPV"(i64* %_bound_ptnum, <4 x double>* %_bound_orient, <4 x double>* %_bound___rest_orient, <3 x double>* %_bound_pivot) #0 {
__llvm_entry:
  %_bound_ptnum1 = load i64, i64* %_bound_ptnum
  %return = call <4 x double> @"point@PISI"(i64 1, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @0, i64 0, i64 0), i64 %_bound_ptnum1)
  %return3 = call double @"getcomp@FPI"(<4 x double> %return, i64 0)
  %return5 = call double @"getcomp@FPI"(<4 x double> %return, i64 1)
  %return7 = call double @"getcomp@FPI"(<4 x double> %return, i64 2)
  %return9 = call double @"getcomp@FPI"(<4 x double> %return, i64 3)
  %return10 = call <4 x double> @"set@PFFFF"(double %return3, double %return5, double %return7, double %return9)
  %_bound_orient11 = load <4 x double>, <4 x double>* %_bound_orient
  %return13 = call <4 x double> @"qmultiply@PPP"(<4 x double> %_bound_orient11, <4 x double> %return10)
  store <4 x double> %return13, <4 x double>* %_bound_orient
  %return15 = call double @"getcomp@FPI"(<4 x double> %return13, i64 3)
  %return16 = call double @"neg@FF"(double 1.000000e+00)
  %return17 = fcmp oeq double %return15, %return16
  br i1 %return17, label %end, label %false

false:                                            ; preds = %__llvm_entry
  br label %end

end:                                              ; preds = %__llvm_entry, %false
  %phi = phi double [ %return15, %false ], [ 1.000000e+00, %__llvm_entry ]
  %tmp = load <4 x double>, <4 x double>* %_bound_orient
  %return21 = call { double, <4 x double> } @"setcomp@FPFI"(<4 x double> %tmp, double %phi, i64 3)
  %output = extractvalue { double, <4 x double> } %return21, 1
  store <4 x double> %output, <4 x double>* %_bound_orient
  store <4 x double> %return, <4 x double>* %_bound___rest_orient
  %_bound_ptnum24 = load i64, i64* %_bound_ptnum
  %return25 = call <3 x double> @"point@VISI"(i64 1, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @1, i64 0, i64 0), i64 %_bound_ptnum24)
  store <3 x double> %return25, <3 x double>* %_bound_pivot
  ret void
}

; Function Attrs: nounwind
declare <4 x double> @"point@PISI"(i64, i8*, i64) #1

; Function Attrs: nounwind readnone
declare double @"getcomp@FPI"(<4 x double>, i64) #2

; Function Attrs: nounwind readnone
declare <4 x double> @"set@PFFFF"(double, double, double, double) #2

; Function Attrs: nounwind readnone
declare <4 x double> @"qmultiply@PPP"(<4 x double>, <4 x double>) #2

; Function Attrs: nounwind readnone
declare double @"neg@FF"(double) #2

; Function Attrs: alwaysinline
define private { double, <4 x double> } @"setcomp@FPFI"(<4 x double> %rw11, double %rw22, i64 %rw33) #3 {
__llvm_entry:
  %rw16 = call <4 x double> @"setcomp@PFI"(<4 x double> %rw11, double %rw22, i64 3)
  %mrv = insertvalue { double, <4 x double> } undef, double %rw22, 0
  %mrv9 = insertvalue { double, <4 x double> } %mrv, <4 x double> %rw16, 1
  ret { double, <4 x double> } %mrv9
}

; Function Attrs: nounwind readnone
declare <4 x double> @"setcomp@PFI"(<4 x double>, double, i64) #2

; Function Attrs: nounwind
declare <3 x double> @"point@VISI"(i64, i8*, i64) #1

; Function Attrs: nounwind
define void @__vex_snippet(i64 %ptnum, <4 x double> %orient, <4 x double> %__rest_orient, <3 x double> %pivot) #1 {
__llvm_entry:
  %"<orient>" = alloca <4 x double>
  %"<__rest_orient>" = alloca <4 x double>
  %"<pivot>" = alloca <3 x double>
  %0 = alloca i64
  store <4 x double> %orient, <4 x double>* %"<orient>"
  store <4 x double> %__rest_orient, <4 x double>* %"<__rest_orient>"
  store <3 x double> %pivot, <3 x double>* %"<pivot>"
  store i64 %ptnum, i64* %0
  call void @"__vex_snippet_snippet@IPPV"(i64* %0, <4 x double>* %"<orient>", <4 x double>* %"<__rest_orient>", <3 x double>* %"<pivot>")
  %gvalue = call i64 @"_export@ISI"(i8* getelementptr inbounds ([6 x i8], [6 x i8]* @2, i64 0, i64 0), i64 %ptnum) #4
  %evalue2 = load <4 x double>, <4 x double>* %"<orient>"
  %gvalue3 = call <4 x double> @"_export@PSP"(i8* getelementptr inbounds ([7 x i8], [7 x i8]* @0, i64 0, i64 0), <4 x double> %evalue2) #4
  %evalue4 = load <4 x double>, <4 x double>* %"<__rest_orient>"
  %gvalue5 = call <4 x double> @"_export@PSP"(i8* getelementptr inbounds ([14 x i8], [14 x i8]* @3, i64 0, i64 0), <4 x double> %evalue4) #4
  %evalue6 = load <3 x double>, <3 x double>* %"<pivot>"
  %gvalue7 = call <3 x double> @"_export@VSV"(i8* getelementptr inbounds ([6 x i8], [6 x i8]* @4, i64 0, i64 0), <3 x double> %evalue6) #4
  store i64 %gvalue, i64* @ptnum
  store <4 x double> %gvalue3, <4 x double>* @orient
  store <4 x double> %gvalue5, <4 x double>* @__rest_orient
  store <3 x double> %gvalue7, <3 x double>* @pivot
  ret void
}

declare i64 @"_export@ISI"(i8*, i64)

declare <4 x double> @"_export@PSP"(i8*, <4 x double>)

declare <3 x double> @"_export@VSV"(i8*, <3 x double>)

define void @__shader_default_arguments() {
__llvm_entry:
  call void @__vex_snippet(i64 0, <4 x double> <double 0.000000e+00, double 0.000000e+00, double 0.000000e+00, double 1.000000e+00>, <4 x double> zeroinitializer, <3 x double> zeroinitializer)
  ret void
}

attributes #0 = { alwaysinline nounwind }
attributes #1 = { nounwind }
attributes #2 = { nounwind readnone }
attributes #3 = { alwaysinline }
attributes #4 = { nounwind readonly }

!context = !{!0}
!version = !{!1}
!precision = !{!2}

!0 = !{!"cvex"}
!1 = !{!"19.0.531"}
!2 = !{!"64"}

;_code_end
